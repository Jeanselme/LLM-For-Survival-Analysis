{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, the goal is two folds:\n",
    "1. Model the different covariates from the text only\n",
    "2. Then model the outcome given the predicted covariates & compare this with model build on the true covariates\n",
    "\n",
    "An important consideration is that we want the split to be the same across all notebooks, we save this information to be sure to be consistent across all experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes  = pd.read_csv('data/TGCA_Merged.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract target labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Adapt this with the structured columns you would like to predict from the unstructured data\n",
    "outcomes_to_predict = outcomes[['type', 'gender', 'race', 'ajcc_pathologic_tumor_stage']]\n",
    "outcomes_to_predict['ajcc_pathologic_tumor_stage'] = outcomes_to_predict.ajcc_pathologic_tumor_stage.astype('category')\n",
    "outcomes_to_predict_dummy = pd.get_dummies(outcomes_to_predict, dummy_na = True).astype(int) # Binarisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes_to_predict_dummy.to_csv('data/binary_embedding.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We propose two different 3 fold cross validation evaluation based on:\n",
    "1. Hospital out evaluation: to ensure that one hospital is only one fold.\n",
    "2. Cancer group: to evaluate how the performance on a suubset of cancer types generalise.\n",
    "\n",
    "The following save how the data should be evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Adapt this split given the columns of your dataset.\n",
    "split = pd.DataFrame({\n",
    "        'Hospital': np.nan,\n",
    "        'Grouping' : np.nan,\n",
    "    }, index = outcomes.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "for split_column in split:\n",
    "    kf = GroupKFold(n_splits = 3)\n",
    "    for i, (_, test_index) in enumerate(kf.split(outcomes, groups = outcomes[split_column])):\n",
    "        split.iloc[test_index] = i\n",
    "split.to_csv('results/split.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run one of the section Embedding, Fine-Tuning or Promptin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding\n",
    "\n",
    "From extracted embedding from LLM try to predict the different covariates of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding to use for the notebook\n",
    "embedding_type = 'BERT' # BERT, clinicalBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = pd.read_csv('data/{}_embedding.csv'.format(embedding_type), index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (outcomes.index == embedding.index).all(), 'Misaligned index may create an issue - How is the embedding obtained?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model the different covariates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We aim to predict from the text each manually extracted covariates. \n",
    "\n",
    "Then we save these covariates for future predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For simplicity, we rely on a NN from sklearn for this task\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = {}\n",
    "for split_type in split.columns:\n",
    "    predictions[split_type] = pd.DataFrame().reindex_like(outcomes_to_predict_dummy)\n",
    "    for fold in split[split_type].dropna().unique():\n",
    "        train = split[split_type].values != fold\n",
    "        test = split[split_type].values == fold\n",
    "\n",
    "        model = MLPClassifier(hidden_layer_sizes = [], random_state = 42, \n",
    "                              learning_rate_init = 0.01, max_iter = 100, \n",
    "                              early_stopping = True).fit(embedding[train].values, outcomes_to_predict_dummy[train].values)\n",
    "        predictions[split_type][test] = model.predict_proba(embedding[test].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.concat(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, \"Go to Section 'Binarise and Save' to save this extraction.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine - Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be careful this will overwrite the previous Section (jump to last to save and evaluate).\n",
    "In this Section, we aim to fine-tune a neural network to extract the concept of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_type = 'clinicalBERT' # clinicalBERT, BERT\n",
    "embedding_type += '_finetune' # For naming distinction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.cuda.is_available(), 'Machine or configuration not using GPU'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(embedding):\n",
    "    if embedding == 'BERT_finetune':\n",
    "        from transformers import BertTokenizer, BertForSequenceClassification\n",
    "        tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels = outcomes_to_predict_dummy.shape[1],\n",
    "            output_attentions = False, output_hidden_states = False, problem_type=\"multi_label_classification\")\n",
    "    elif embedding == 'clinicalBERT_finetune':\n",
    "        from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "        tokenizer = DistilBertTokenizer.from_pretrained('medicalai/ClinicalBERT')\n",
    "        model = DistilBertForSequenceClassification.from_pretrained(\"medicalai/ClinicalBERT\", num_labels = outcomes_to_predict_dummy.shape[1],\n",
    "            output_attentions = False, output_hidden_states = False, problem_type=\"multi_label_classification\")\n",
    "\n",
    "    return tokenizer, model\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels.values\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx]).float()\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(output_dir = 'results/', num_train_epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = {}\n",
    "for split_type in split.columns:\n",
    "    predictions[split_type] = pd.DataFrame().reindex_like(outcomes_to_predict_dummy)\n",
    "    for fold in split[split_type].dropna().unique():\n",
    "        train = split[split_type].values != fold\n",
    "        test = split[split_type].values == fold\n",
    "\n",
    "        # Load model and encode data\n",
    "        tokenizer, model = get_model(embedding_type)\n",
    "        train_endcoded = Dataset(tokenizer(outcomes[train].text.tolist(), truncation = True, padding = True), outcomes_to_predict_dummy[train])\n",
    "        test_endcoded = Dataset(tokenizer(outcomes[test].text.tolist(), truncation = True, padding = True), outcomes_to_predict_dummy[test])\n",
    "\n",
    "        # Train model\n",
    "        trainer = Trainer(model = model, args = training_args, \n",
    "                          train_dataset = train_endcoded)\n",
    "        trainer.train()\n",
    "\n",
    "        # Predict\n",
    "        predictions[split_type][test] = trainer.predict(test_endcoded).predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.concat(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, \"Go to Section 'Binarise and Save' to save this extraction.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipeline(\"text-generation\", model=\"medalpaca/medalpaca-7b\", tokenizer=\"medalpaca/medalpaca-7b\") # Should be downloaded in my folder (10 Gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes_match = {\n",
    "    \"type\": (\"cancer_type\", outcomes_to_predict[\"type\"].dropna().unique()),\n",
    "    \"gender\": ('sex', ['male', 'female']),\n",
    "    \"race\": ('ethnicity', ['white', 'non-white']),\n",
    "    \"ajcc_pathologic_tumor_stage\": ('Cancer stage', ['I', 'II', 'III'])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binarised_predictions = pd.DataFrame().reindex_like(outcomes_to_predict)\n",
    "for outcome in outcomes_to_predict:\n",
    "    name, values = outcomes_match[outcome]\n",
    "    for patient in binarised_predictions.index:\n",
    "        patient_text = outcomes.text[patient]\n",
    "        prompt = \"Context: Pathology report {}\\n\\n Question: Based on the provided pathology report, what is the {} (possible values: {})? Please provide your answer as one of these values, without any additional text or explanations.\\n\\nAnswer:\".format(patient_text, name, values)\n",
    "        binarised_predictions.loc[patient, outcome] = model(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binarised_predictions.to_csv('data/alpaca_predicted_binary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, \"You are done ! This method does not require binarisations.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discretise and save\n",
    "\n",
    "As the previous sections predict probabilities, we then discretise the outputs to match the concept of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarisation by a softmax\n",
    "binarised_predictions = []\n",
    "for column in outcomes_to_predict.columns:\n",
    "    if column == 'ajcc_pathologic_tumor_stage': # Special float case\n",
    "        pred_col = predictions.loc[:, predictions.columns.str.contains(column)].idxmax(axis = 1).str.replace(column + '_', '').astype(float)\n",
    "    elif column == 'type': # Special categorial case (change for other dataset)\n",
    "        pred_col = predictions.loc[:, predictions.columns.str.contains(column)].idxmax(axis = 1).str.replace(column + '_', '')\n",
    "    else: # All other binary variable\n",
    "        pred_col = predictions.loc[:, column] > 0.5\n",
    "\n",
    "    binarised_predictions.append(pred_col.rename(column))\n",
    "binarised_predictions = pd.concat(binarised_predictions, axis = 1)\n",
    "binarised_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binarised_predictions.to_csv('data/{}_predicted_binary.csv'.format(embedding_type))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have now saved the predicted binary outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure performance of the extraction\n",
    "\n",
    "This section allows you to check the performance for extracting the concetps of interest. Maybe the text does not contain the information or any indicator of the conctept you aim to extract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = {}\n",
    "for split_type in split.columns:\n",
    "    columns = split[split_type].dropna().unique()\n",
    "    performance[split_type] = pd.DataFrame(index = columns, columns = predictions.columns)\n",
    "    for fold in columns:\n",
    "        for dimension in predictions.columns:\n",
    "            test = split[split_type] == fold\n",
    "            mean = outcomes_to_predict_dummy.loc[test, dimension].mean()\n",
    "            if mean != 1 and mean != 0:\n",
    "                # The class contains some positive\n",
    "                performance[split_type].loc[fold, dimension] = roc_auc_score(outcomes_to_predict_dummy.loc[test, dimension], predictions.loc[(split_type, test[test].index), dimension])\n",
    "performance = pd.concat(performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance.loc['Hospital'].astype(float).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance.loc['Grouping'].astype(float).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
