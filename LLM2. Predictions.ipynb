{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook runs a Cox model to predict the survival outcome in a cross validation fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "import torchtuples as tt\n",
    "from pycox.models import CoxPH\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sksurv.nonparametric import kaplan_meier_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose embedding to run the experiment on (consider both _predicted_binary.csv and _embedding.csv)\n",
    "embedding_type = 'BERT_predicted_binary'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "embedding = pd.read_csv('data/{}.csv'.format(embedding_type), index_col = [0, 1] if 'predicted' in embedding_type else [0])\n",
    "outcomes = pd.read_csv('data/TGCA_Merged.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'binary' in embedding_type:\n",
    "    # Avoid nan issue\n",
    "    embedding.ajcc_pathologic_tumor_stage = embedding.ajcc_pathologic_tumor_stage.astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load splits\n",
    "split = pd.read_csv('results/split.csv', index_col = [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_predict(data, index_train, index_val, index_test, prediction_times):\n",
    "    \"\"\"\n",
    "        Function to train a Cox model and predict the outcome\n",
    "\n",
    "        Args:\n",
    "            index_train (list): index used to train model.\n",
    "            index_val (list): index used to stop training.\n",
    "            index_test (list): index used to test.\n",
    "            prediction_times (list float): Times to predict survival.\n",
    "\n",
    "        Returns:\n",
    "            DataFrame (len(index_test) * len(prediction_times)) - Predictions for each patients at the difference time horizons\n",
    "    \"\"\"\n",
    "    trans = lambda x: x.values.astype('float32')\n",
    "    np.random.seed(42)\n",
    "\n",
    "    ## Define NN connecting embedding to Cox\n",
    "    net = tt.practical.MLPVanilla(data.shape[1], [], 1, True, 0.1, output_bias = False)\n",
    "    model = CoxPH(net, tt.optim.Adam)\n",
    "\n",
    "    ## Train\n",
    "    model.fit(trans(data.loc[index_train]), (trans(outcomes.loc[index_train].t), trans(outcomes.loc[index_train].e)), \n",
    "            batch_size = 100, epochs = 500, callbacks = [tt.callbacks.EarlyStopping()], verbose = False,\n",
    "            val_data = (trans(data.loc[index_val]), (trans(outcomes.loc[index_val].t), trans(outcomes.loc[index_val].e))))\n",
    "    _ = model.compute_baseline_hazards() # Fit the non-parametric baseline\n",
    "\n",
    "    ## Predict and interpolate\n",
    "    embed_test = data.loc[index_test]\n",
    "    pred = model.predict_surv_df(trans(embed_test))\n",
    "    pred.columns = embed_test.index\n",
    "    \n",
    "    pred_times = pd.DataFrame(np.nan, columns = pred.columns, index = prediction_times)\n",
    "    pred = pd.concat([pred, pred_times], axis = 0).sort_index(kind = 'stable').bfill().ffill()\n",
    "    pred = pred[~pred.index.duplicated(keep='first')]\n",
    "    pred = pred.loc[prediction_times]\n",
    "    return pred.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to predict outcomes\n",
    "prediction_times = np.linspace(0, outcomes.t.max(), 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = {}\n",
    "for split_type in split.columns:\n",
    "    predictions[split_type] = pd.DataFrame(index = split.index, columns = prediction_times)\n",
    "    embed = pd.get_dummies(embedding.loc[split_type]) if 'predicted' in embedding_type else embedding # If only cross validated - Use the same\n",
    "    for fold in split[split_type].dropna().unique():\n",
    "        train = split[split_type] != fold\n",
    "        train = train[train].index\n",
    "        train, val = train_test_split(train, test_size = 0.2, random_state = 42) \n",
    "        test = split[split_type] == fold\n",
    "        predictions[split_type][test] = train_and_predict(embed, train, val, test, prediction_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.concat(predictions)\n",
    "predictions.to_csv('results/{}_predictions.csv'.format(embedding_type))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does adding manually extracted features improve performance ?\n",
    "The hypothesis is that info in the text might be *complementary*, not replacing the other features.\n",
    "\n",
    "To evaluate, run the following code that concat the binary embedding with the other you are considering and use it for prediction. \n",
    "\n",
    "To also investigate if thesimple features are more useful then the embedding, run the previous code with the embedding binary_embedding.csv (jsut cahnge the embedding_type variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 'binary' not in embedding_type, 'Not useful to combine these embeddings'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_binary = pd.read_csv('data/binary_embedding.csv', index_col = [0])\n",
    "concatenated_emb = pd.concat([embedding, embedding_binary], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = {}\n",
    "for split_type in split.columns:\n",
    "    predictions[split_type] = pd.DataFrame(index = split.index, columns = prediction_times)\n",
    "    for fold in split[split_type].dropna().unique():\n",
    "        train = split[split_type] != fold\n",
    "        train = train[train].index\n",
    "        train, val = train_test_split(train, test_size = 0.2, random_state = 42) \n",
    "        test = split[split_type] == fold\n",
    "        predictions[split_type][test] = train_and_predict(concatenated_emb, train, val, test, prediction_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.concat(predictions)\n",
    "predictions.to_csv('results/{}_concat_predictions.csv'.format(embedding_type))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
